\chapter{Introduction}\label{chap:introduction}



\section*{}

This chapter provides and overview about the research context, motivation, objectives along with the research areas / questions and the outline of this thesis proposal.



\section{Context and motivation}

Automation of repetitive tasks using robots has revolutionized industrial manufacturing for a very long time, allowing mass production of a wide range of products at reduced cost and improved quality. However, these robotic systems are usually programmed off-line for very specific assignments and require long and expensive re-programming to perform different assembly operations.

The development of more cooperative robotic arm designs along with better perception sensors opened new possibilities for improving the flexibility of manufacturing lines, allowing jobs that are currently being performed by humans (due to its assembly complexity or cognitive requirements) to be transitioned to hybrid human-robot systems \cite{Surdilovic2010}. This cooperative approach allows to improve overall assembly productivity by allowing the human operator to teach the robot the skills necessary to perform the assembly operations and rely on the human partner for the more challenging tasks that require higher levels of cognition and dexterity.

Human-robot interaction systems capable of learning from demonstration provide great flexibility to industrial applications in which the assembly lines have limited / customized production \cite{Patel2012}. They offer fast reprogramming of robots and allow cooperative assembly of complex and delicate tasks \cite{Sumi2009,Edsinger2007}. These systems can perform active perception of the environment \cite{Yan2014,Goodrich2007} with a wide range of sensors (\gls{tof}, RGB-D, visual, audio, tactile, laser) and a multitude of recognition algorithms such as visual / geometric feature association, template / shape matching, color / intensity / texture segmentation (among many others). Moreover, by semantic analyzing the operator movements \cite{Roitberg2014} through hand / skeletal tracking they are able to extract the skills / knowledge \cite{Nikolaidis14,Goto2013} that is required to assemble a new composite object. Besides learning new assembly skills through techniques such as \glspl{svm}, clustering, \glspl{nn}, \glspl{dt}, boosting, \glspl{hmm}, \glspl{gmm} (to name a few), these perception systems can also be used to implement communication protocols, allowing a more natural interaction (gesture, posture, voice) between the robot and the operator \cite{Gleeson2013,Calisgan2012,Haddadi2013}.

The promising industrial applications of cognitive robotics in manufacturing lines lead to the creation of several research projects, such as Saphari\footnote{\url{http://www.saphari.eu}}, Rosetta\footnote{\url{http://www.fp7rosetta.org}}, JAHIR\footnote{\url{http://www6.in.tum.de/Main/ResearchJahir}}, Charm\footnote{\url{http://charm.stanford.edu}}, RoboEarth\footnote{\url{http://roboearth.org}}, KnowRob\footnote{\url{http://www.knowrob.org}}, ROS-Industrial\footnote{\url{http://rosindustrial.org}} (among many others).



\section{Objectives}

The main objective of this thesis is to devise a flexible framework for human-robot cooperative assembly capable of semantic learning by demonstration in order to improve the flexibility and efficiency of complex industrial assembly tasks by relying on the robot's precision / speed skills and on the human knowledge / dexterity. To achieve the mentioned cooperation in assembly tasks, the system will need to recognize and track the assembly components using 3D perception and must also be able to semantically analyze human movements in order to learn new skills or receive new commands from the operator. These learning skills will rely on \gls{cad} / \gls{sop} analysis, cumulative assembly knowledge and will be shared across robotic arms with different hardware configurations through the usage of a common skill / knowledge database.

To enhance the cooperation with the operator, the system will provide an augmented reality interface in order to display relevant learning / assembly information and also inform the operator of missing / wrong assembly components. Moreover, this interface will allow an immersive and intuitive way of inspecting and manipulating the assembly system knowledge and will ease the human-robot cooperation when the assembly tasks alternate between the operator and the robotic system.

Expected contributions include not only the formalization of generic skills, reusable in different robots and in different parts but also proposing additional human-robot strategies for improved flexibility in industrial assembly tasks.

The proposed approaches will be validated in simulation and in real hardware, with the assembly of several complex objects using different types of robotic arms in order to test the learning skills along with the perception and manipulation sub-systems. These objects will be selected based on their assembly complexity and their type of demand seen in industrial scenarios.



\section{Research areas}

Automation of assembly tasks requires multidisciplinary knowledge in the following research fields:

\begin{itemize}
	\item Machine Learning
	\begin{itemize}
		\item Learning new assembly skills by demonstration
	\end{itemize}
	\item Computer Vision, 3D perception and Human Machine Interface
	\begin{itemize}
		\item Recognition and tracking of assembly objects
		\item Detection of operator movements for semantic assembly analysis and user interface
	\end{itemize}
	\item Augmented Reality
	\begin{itemize}
		\item Projection of information into the workspace to help the human operator
		\begin{itemize}
			\item Informing the operator which object it should pick and where it should place it
		\end{itemize}
	\end{itemize}
	\item Natural Language Processing
	\begin{itemize}
		\item Extraction of assembly information from instruction manuals or \glspl{sop}
		\item Recognition of voice commands from the human operator
	\end{itemize}
	\item Industrial robotics
	\begin{itemize}
		\item Development of abstract and reusable knowledge that can be employed in robots with different hardware configurations
	\end{itemize}
\end{itemize}



\section{Research questions}

The main research questions for this thesis proposal are the following:

\begin{itemize}
	\item How to reliably learn new assembly skills by demonstration given that the tracking of the assembly objects will always have pose estimation errors and temporary occlusions by the operator?
	\item How to automatically extract assembly information from \gls{cad} / \gls{sop} data?
	\item How to generalize a specific assembly skill and reuse it to perform similar tasks?
	\item How to efficiently coordinate complex assembly procedures between humans and robots in a shared work space?
\end{itemize}



\section{Proposal outline}

The remaining of this document is split over 4 chapters. \Cref{chap:related-work} introduces the main related work, giving an overview of the knowledge developed over the years in the areas of industrial robotics, environment perception, machine learning and human-machine interaction. \Cref{chap:preliminary-work} describes some preliminary work done in the area of projection mapping using \gls{dlp} and laser projectors for cooperative welding operations. \Cref{chap:work-plan} gives a detailed description of the tasks planned for the next 3 years. Finally, \cref{chap:conclusions-and-future-work} presents the conclusions of this thesis proposal.
