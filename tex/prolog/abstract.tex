\chapter*{Abstract}

Assembly of complex structures is a challenging task that requires multidisciplinary knowledge and high level of precision. In the past this was mostly achieved with teach pendant programming and more recently by means of lead through programming. The development of new sensors and the significant increase in computation capabilities opened new possibilities regarding robotic (re)programing, allowing mass customization of products. This project aims to provide an intuitive, immersive and easy to use robot assembly system, capable of semantic learning through demonstration and cooperating with humans in complex tasks. The combination of pre-existing knowledge (\gls{cad}, \glspl{sop}) with object localization and semantic interpretation of the operator movements will allow the definition of reusable assembly operations. Moreover, to improve the human-robot interaction, an immersive interface using augmented reality will provide a fast and intuitive way to exchange knowledge and improve cooperation between the assembly system and the human operator.
